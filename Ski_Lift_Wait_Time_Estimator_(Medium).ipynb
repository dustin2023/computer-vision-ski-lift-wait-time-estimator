{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCjB0bYgidcL"
   },
   "source": [
    "# Load packages and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KJmlmUtcNnV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Erkenne, ob wir auf Colab laufen\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive, files\n",
    "\n",
    "    drive.mount(\"/content/drive\", force_remount=True)\n",
    "    BASE_PATH = \"/content\"\n",
    "    print(\"✓ Google Colab erkannt\")\n",
    "else:\n",
    "    BASE_PATH = str(Path.home() / \"ski_lift_data\")\n",
    "    os.makedirs(BASE_PATH, exist_ok=True)\n",
    "    print(f\"✓ Lokaler Modus: {BASE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "YCwQzPtvf52f",
    "outputId": "51a862c8-a088-4bc8-bf26-042aaf088fe9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-173545f6-e1f3-444b-a8b1-f2a6f8e1ec10\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-173545f6-e1f3-444b-a8b1-f2a6f8e1ec10\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving take5.mov to take5.mov\n"
     ]
    }
   ],
   "source": [
    "# select file, if not running 'live' mode\n",
    "if IS_COLAB:\n",
    "    print(\"\\nÜploadiere deine Datei (optional):\")\n",
    "    uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "vStIcLG9AESs",
    "outputId": "d9bef081-628b-43c6-d685-0fee9d56cb0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "✓ Using CPU for inference\n",
      "Logging to: /Users/dustin/dev/computer-vision-ski-lift-wait-time-estimator/ski_cam_logs/roi_counts_20251215_105248.csv\n",
      "Bergfex mode: extracting image URL...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not extract webcam ID from URL: https://www.feratel.com/webcams/oesterreich/tirol/scheffau-am-wilden-kaiser-brandstadl-restaurant",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 207\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m MODE == \u001b[33m\"\u001b[39m\u001b[33mbergfex\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    206\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBergfex mode: extracting image URL...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     bergfex_image_url = \u001b[43mextract_bergfex_image_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbergfex_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m     \u001b[38;5;66;03m# Fetch first image to get dimensions\u001b[39;00m\n\u001b[32m    210\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFetching initial image...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 152\u001b[39m, in \u001b[36mextract_bergfex_image_url\u001b[39m\u001b[34m(page_url)\u001b[39m\n\u001b[32m    150\u001b[39m match = re.search(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m/c(\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md+)/?\u001b[39m\u001b[33m'\u001b[39m, page_url)\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m match:\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not extract webcam ID from URL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    154\u001b[39m webcam_id = match.group(\u001b[32m1\u001b[39m)\n\u001b[32m    155\u001b[39m image_url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttp://images.bergfex.at/webcams/?id=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwebcam_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Could not extract webcam ID from URL: https://www.feratel.com/webcams/oesterreich/tirol/scheffau-am-wilden-kaiser-brandstadl-restaurant"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# INSTALLS & IMPORTS\n",
    "# ============================================================\n",
    "# !pip install ultralytics yt-dlp -q\n",
    "\n",
    "import cv2, time, subprocess, shlex, os, csv, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import display, clear_output, DisplayHandle\n",
    "from PIL import Image\n",
    "from zoneinfo import ZoneInfo\n",
    "from collections import deque\n",
    "import torch\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SETTINGS\n",
    "# ============================================================\n",
    "\n",
    "MODE = \"live\"  # \"file\", \"live\", or \"bergfex\"\n",
    "\n",
    "# Base paths (local-friendly)\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "# File mode\n",
    "input_video = os.path.join(BASE_DIR, \"your_video.mov\")\n",
    "\n",
    "# Live mode (YouTube)\n",
    "youtube_url = \"https://www.youtube.com/watch?v=wooEGQw9yrw\"\n",
    "COOKIES_PATH = None  # optional, for age-restricted streams\n",
    "\n",
    "# Bergfex mode (static image polling)\n",
    "bergfex_url = \"https://www.bergfex.ch/st-moritz-corviglia/webcams/c5844/\"  # example URL\n",
    "BERGFEX_POLL_INTERVAL = 5  # seconds between image fetches\n",
    "\n",
    "# Preview (optimized for real-time)\n",
    "LIVE_PREVIEW = True\n",
    "PREVIEW_EVERY = 1  # show every frame for real-time preview\n",
    "\n",
    "# Debug\n",
    "DEBUG_MODE = True\n",
    "DEBUG_PRINT_EVERY = 30\n",
    "\n",
    "# Loop limits (to prevent endless loops)\n",
    "MAX_FRAMES = 1200  # stop after ~10 min at 2 fps\n",
    "MAX_SECONDS = 300  # stop after 5 minutes\n",
    "FRAME_SKIP = 0  # skip frames for faster processing (0 = no skip)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# DETECTION PARAMETERS\n",
    "# ============================================================\n",
    "\n",
    "CONF_THRESHOLD = 0.25  # higher = fewer false positives (try 0.25–0.45)\n",
    "IOU_THRESHOLD = 0.9  # higher = less merging of nearby detections\n",
    "MIN_MASK_AREA = 200  # filter out tiny fragments\n",
    "PERSON_CLASS_ONLY = True\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MODEL & GPU/CPU\n",
    "# ============================================================\n",
    "\n",
    "# Use smaller, faster model for real-time inference\n",
    "model = YOLO(\"yolo11s-seg.pt\")\n",
    "\n",
    "# Auto-detect GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    model.to(\"cuda\")\n",
    "    print(\"✓ Using GPU (CUDA) for inference\")\n",
    "else:\n",
    "    print(\"✓ Using CPU for inference\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ROI CONFIG\n",
    "# ============================================================\n",
    "\n",
    "# Reference resolution (what your ROI coords are based on)\n",
    "REF_WIDTH = 2090\n",
    "REF_HEIGHT = 1164\n",
    "\n",
    "# ROI bounding box (adjust for your camera)\n",
    "BASE_ROI_X1, BASE_ROI_Y1 = 200, 500\n",
    "BASE_ROI_X2, BASE_ROI_Y2 = 950, 900\n",
    "\n",
    "SCALE = 2.5  # upscale factor for better detection on small regions\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# LOGGING\n",
    "# ============================================================\n",
    "\n",
    "TZ = ZoneInfo(\"Europe/Berlin\")\n",
    "SESSION_START = datetime.datetime.now(TZ).strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "LOG_DIR = os.path.join(BASE_DIR, \"ski_cam_logs\")\n",
    "LOG_PATH = os.path.join(LOG_DIR, f\"roi_counts_{SESSION_START}.csv\")\n",
    "\n",
    "SMOOTH_WINDOW_SEC = 15\n",
    "history = deque()\n",
    "\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "log_file = open(LOG_PATH, \"w\", newline=\"\")\n",
    "log_writer = csv.writer(log_file)\n",
    "log_writer.writerow(\n",
    "    [\n",
    "        \"frame_idx\",\n",
    "        \"epoch_time\",\n",
    "        \"local_time\",\n",
    "        \"raw_count\",\n",
    "        \"smoothed_count\",\n",
    "        \"filtered_out_count\",\n",
    "    ]\n",
    ")\n",
    "log_file.flush()\n",
    "\n",
    "print(f\"Logging to: {LOG_PATH}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SCREENSHOTS (live mode only)\n",
    "# ============================================================\n",
    "\n",
    "SCREENSHOT_DIR = os.path.join(BASE_DIR, \"screenshots\")\n",
    "os.makedirs(SCREENSHOT_DIR, exist_ok=True)\n",
    "\n",
    "SCREENSHOT_THRESHOLD = 20\n",
    "SCREENSHOT_COOLDOWN = 10\n",
    "last_screenshot_time = 0.0\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# BERGFEX URL PARSER\n",
    "# ============================================================\n",
    "\n",
    "def extract_bergfex_image_url(page_url):\n",
    "    \"\"\"\n",
    "    Extract direct image URL from bergfex webcam page.\n",
    "    Pattern: https://www.bergfex.at/.../webcams/c<ID>/ -> http://images.bergfex.at/webcams/?id=<ID>\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Extract ID from URL (e.g., c114 -> 114)\n",
    "    match = re.search(r'/c(\\d+)/?', page_url)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Could not extract webcam ID from URL: {page_url}\")\n",
    "    \n",
    "    webcam_id = match.group(1)\n",
    "    image_url = f\"http://images.bergfex.at/webcams/?id={webcam_id}\"\n",
    "    \n",
    "    print(f\"✓ Extracted webcam ID: {webcam_id}\")\n",
    "    print(f\"✓ Image URL: {image_url}\")\n",
    "    \n",
    "    return image_url\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# INITIALIZE VIDEO CAPTURE\n",
    "# ============================================================\n",
    "\n",
    "cap = None\n",
    "bergfex_image_url = None\n",
    "last_bergfex_fetch = 0\n",
    "\n",
    "if MODE == \"file\":\n",
    "    print(f\"File mode: {input_video}\")\n",
    "    cap = cv2.VideoCapture(input_video)\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    output_video = os.path.join(BASE_DIR, \"output_overlay.mp4\")\n",
    "    out = cv2.VideoWriter(output_video, fourcc, fps, (W, H))\n",
    "\n",
    "elif MODE == \"live\":\n",
    "    print(\"Live mode: resolving YouTube stream...\")\n",
    "\n",
    "    cmd = f'yt-dlp -f best -g \"{youtube_url}\"'\n",
    "    if COOKIES_PATH and os.path.exists(COOKIES_PATH):\n",
    "        cmd = f'yt-dlp --cookies \"{COOKIES_PATH}\" -f best -g \"{youtube_url}\"'\n",
    "\n",
    "    proc = subprocess.Popen(\n",
    "        shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
    "    )\n",
    "    stdout, stderr = proc.communicate()\n",
    "    stream_url = stdout.decode().strip().split(\"\\n\")[0]\n",
    "\n",
    "    if not stream_url:\n",
    "        print(\"Error:\", stderr.decode())\n",
    "        raise RuntimeError(\"Could not resolve stream URL\")\n",
    "\n",
    "    print(f\"Stream URL: {stream_url[:80]}...\")\n",
    "    cap = cv2.VideoCapture(stream_url)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Stream could not be opened. Check URL/Cookies/yt-dlp.\")\n",
    "\n",
    "elif MODE == \"bergfex\":\n",
    "    print(\"Bergfex mode: extracting image URL...\")\n",
    "    bergfex_image_url = extract_bergfex_image_url(bergfex_url)\n",
    "    \n",
    "    # Fetch first image to get dimensions\n",
    "    print(\"Fetching initial image...\")\n",
    "    response = requests.get(bergfex_image_url, timeout=10)\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(f\"Could not fetch image. HTTP {response.status_code}\")\n",
    "    \n",
    "    img_array = np.frombuffer(response.content, dtype=np.uint8)\n",
    "    frame = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    if frame is None:\n",
    "        raise RuntimeError(\"Could not decode image from bergfex\")\n",
    "    \n",
    "    H, W = frame.shape[:2]\n",
    "    print(f\"✓ Image size: {W}x{H}\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"MODE must be 'file', 'live', or 'bergfex'\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SCALE ROI TO STREAM RESOLUTION\n",
    "# ============================================================\n",
    "\n",
    "if cap is not None:\n",
    "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "print(f\"Stream: {W}x{H}, Reference: {REF_WIDTH}x{REF_HEIGHT}\")\n",
    "\n",
    "scale_x = W / REF_WIDTH\n",
    "scale_y = H / REF_HEIGHT\n",
    "\n",
    "roi_x1 = int(BASE_ROI_X1 * scale_x)\n",
    "roi_y1 = int(BASE_ROI_Y1 * scale_y)\n",
    "roi_x2 = int(BASE_ROI_X2 * scale_x)\n",
    "roi_y2 = int(BASE_ROI_Y2 * scale_y)\n",
    "\n",
    "roi_polygon = [(roi_x1, roi_y1), (roi_x2, roi_y1), (roi_x2, roi_y2), (roi_x1, roi_y2)]\n",
    "roi_np = np.array(roi_polygon, np.int32)\n",
    "\n",
    "print(f\"ROI: ({roi_x1}, {roi_y1}) to ({roi_x2}, {roi_y2})\")\n",
    "\n",
    "\n",
    "def inside_roi(x, y):\n",
    "    poly = np.array(roi_polygon, np.int32)\n",
    "    return cv2.pointPolygonTest(poly, (x, y), False) >= 0\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN LOOP\n",
    "# ============================================================\n",
    "\n",
    "frame_idx = 0\n",
    "display_handle = DisplayHandle()\n",
    "display_handle.display(\"Waiting for first frame...\")\n",
    "last_preview_time = time.time()\n",
    "preview_fps = 0\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "\n",
    "    # Check exit conditions\n",
    "    elapsed = time.time() - start_time\n",
    "    if frame_idx >= MAX_FRAMES:\n",
    "        print(f\"\\n⚠️ Reached MAX_FRAMES ({MAX_FRAMES}). Stopping.\")\n",
    "        break\n",
    "    if elapsed >= MAX_SECONDS:\n",
    "        print(f\"\\n⚠️ Reached MAX_SECONDS ({MAX_SECONDS}). Stopping.\")\n",
    "        break\n",
    "\n",
    "    # Fetch frame based on mode\n",
    "    if MODE == \"bergfex\":\n",
    "        # Poll-based: only fetch if enough time has passed\n",
    "        now = time.time()\n",
    "        if (now - last_bergfex_fetch) >= BERGFEX_POLL_INTERVAL:\n",
    "            try:\n",
    "                response = requests.get(bergfex_image_url, timeout=10)\n",
    "                if response.status_code == 200:\n",
    "                    img_array = np.frombuffer(response.content, dtype=np.uint8)\n",
    "                    frame = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "                    last_bergfex_fetch = now\n",
    "                    ret = frame is not None\n",
    "                else:\n",
    "                    print(f\"⚠️ HTTP {response.status_code}, skipping frame\")\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error fetching bergfex image: {e}\")\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "        else:\n",
    "            # Wait until next poll interval\n",
    "            time.sleep(0.1)\n",
    "            continue\n",
    "    else:\n",
    "        # Video/stream mode\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        if MODE == \"live\":\n",
    "            time.sleep(0.1)\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Skip frames if configured\n",
    "    if FRAME_SKIP > 0 and frame_idx % (FRAME_SKIP + 1) != 0:\n",
    "        frame_idx += 1\n",
    "        continue\n",
    "\n",
    "    annotated = frame.copy()\n",
    "\n",
    "    # Crop and upscale ROI\n",
    "    roi_crop = frame[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "    roi_up = cv2.resize(roi_crop, (0, 0), fx=SCALE, fy=SCALE)\n",
    "\n",
    "    # Run YOLO segmentation\n",
    "    results = model.predict(\n",
    "        roi_up, conf=CONF_THRESHOLD, iou=IOU_THRESHOLD, verbose=False\n",
    "    )\n",
    "\n",
    "    masks = results[0].masks\n",
    "    boxes = results[0].boxes\n",
    "\n",
    "    ids_in_roi = []\n",
    "    filtered_out = 0\n",
    "    debug_info = []\n",
    "\n",
    "    # Process masks\n",
    "    if masks is not None:\n",
    "        for i, mask in enumerate(masks.data):\n",
    "\n",
    "            if PERSON_CLASS_ONLY:\n",
    "                cls_id = int(boxes.cls[i])\n",
    "                if cls_id != 0:\n",
    "                    filtered_out += 1\n",
    "                    continue\n",
    "\n",
    "            m = mask.cpu().numpy().astype(np.uint8)\n",
    "\n",
    "            if m.sum() == 0:\n",
    "                filtered_out += 1\n",
    "                continue\n",
    "\n",
    "            # Resize mask to original ROI size\n",
    "            mask_full = cv2.resize(\n",
    "                m, (roi_x2 - roi_x1, roi_y2 - roi_y1), interpolation=cv2.INTER_NEAREST\n",
    "            )\n",
    "            mask_region = mask_full.astype(bool)\n",
    "\n",
    "            ys_resized, xs_resized = np.where(mask_full > 0)\n",
    "\n",
    "            if len(xs_resized) == 0:\n",
    "                filtered_out += 1\n",
    "                continue\n",
    "\n",
    "            mask_area = len(xs_resized)\n",
    "            if mask_area < MIN_MASK_AREA:\n",
    "                filtered_out += 1\n",
    "                continue\n",
    "\n",
    "            # Compute centroid\n",
    "            cx_roi = xs_resized.mean()\n",
    "            cy_roi = ys_resized.mean()\n",
    "            cx_full = int(cx_roi + roi_x1)\n",
    "            cy_full = int(cy_roi + roi_y1)\n",
    "\n",
    "            is_counted = inside_roi(cx_full, cy_full)\n",
    "\n",
    "            if is_counted:\n",
    "                ids_in_roi.append(i)\n",
    "                conf = float(boxes.conf[i])\n",
    "                debug_info.append(\n",
    "                    {\n",
    "                        \"id\": i,\n",
    "                        \"conf\": conf,\n",
    "                        \"area\": mask_area,\n",
    "                        \"cx\": cx_full,\n",
    "                        \"cy\": cy_full,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            # Draw mask overlay\n",
    "            color = (0, 255, 0) if is_counted else (0, 150, 0)\n",
    "            alpha = 0.45 if is_counted else 0.25\n",
    "\n",
    "            roi_slice = annotated[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "            overlay = roi_slice.copy()\n",
    "            overlay[mask_region] = color\n",
    "            roi_slice[mask_region] = cv2.addWeighted(\n",
    "                roi_slice, 1 - alpha, overlay, alpha, 0\n",
    "            )[mask_region]\n",
    "            annotated[roi_y1:roi_y2, roi_x1:roi_x2] = roi_slice\n",
    "\n",
    "            if DEBUG_MODE and is_counted:\n",
    "                cv2.circle(annotated, (cx_full, cy_full), 6, (0, 0, 255), -1)\n",
    "                cv2.circle(annotated, (cx_full, cy_full), 6, (255, 255, 255), 2)\n",
    "\n",
    "    # Debug print\n",
    "    if DEBUG_MODE and frame_idx % DEBUG_PRINT_EVERY == 0 and debug_info:\n",
    "        print(f\"\\n--- Frame {frame_idx} ---\")\n",
    "        print(f\"Counted: {len(ids_in_roi)}, Filtered: {filtered_out}\")\n",
    "        for d in debug_info:\n",
    "            print(\n",
    "                f\"  #{d['id']}: conf={d['conf']:.2f}, area={d['area']}, pos=({d['cx']}, {d['cy']})\"\n",
    "            )\n",
    "\n",
    "    # Logging + smoothing\n",
    "    now_epoch = time.time()\n",
    "    local_dt = datetime.datetime.fromtimestamp(now_epoch, TZ)\n",
    "    local_str = local_dt.strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "\n",
    "    raw_count = len(ids_in_roi)\n",
    "\n",
    "    history.append((now_epoch, raw_count))\n",
    "    while history and (now_epoch - history[0][0] > SMOOTH_WINDOW_SEC):\n",
    "        history.popleft()\n",
    "\n",
    "    smooth_count = sum(c for _, c in history) / len(history) if history else 0.0\n",
    "\n",
    "    log_writer.writerow(\n",
    "        [frame_idx, now_epoch, local_str, raw_count, smooth_count, filtered_out]\n",
    "    )\n",
    "\n",
    "    if frame_idx % 120 == 0:\n",
    "        log_file.flush()\n",
    "\n",
    "    # Draw overlays\n",
    "    cv2.polylines(annotated, [roi_np], True, (0, 255, 0), 3)\n",
    "\n",
    "    cv2.putText(\n",
    "        annotated,\n",
    "        f\"Raw: {raw_count}   Smooth({SMOOTH_WINDOW_SEC}s): {smooth_count:.1f}\",\n",
    "        (20, 40),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        1.0,\n",
    "        (0, 255, 0),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "    cv2.putText(\n",
    "        annotated, local_str, (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2\n",
    "    )\n",
    "\n",
    "    if DEBUG_MODE:\n",
    "        cv2.putText(\n",
    "            annotated,\n",
    "            f\"Filtered: {filtered_out} | Conf>{CONF_THRESHOLD} | Area>{MIN_MASK_AREA}\",\n",
    "            (20, 120),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.6,\n",
    "            (0, 200, 255),\n",
    "            2,\n",
    "        )\n",
    "\n",
    "    # Mode indicator\n",
    "    mode_text = f\"Mode: {MODE.upper()}\"\n",
    "    if MODE == \"bergfex\":\n",
    "        mode_text += f\" ({BERGFEX_POLL_INTERVAL}s poll)\"\n",
    "    cv2.putText(\n",
    "        annotated,\n",
    "        mode_text,\n",
    "        (W - 300, 40),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.7,\n",
    "        (255, 255, 0),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "    # Screenshots (live/bergfex mode)\n",
    "    if (\n",
    "        MODE in [\"live\", \"bergfex\"]\n",
    "        and raw_count >= SCREENSHOT_THRESHOLD\n",
    "        and (now_epoch - last_screenshot_time) > SCREENSHOT_COOLDOWN\n",
    "    ):\n",
    "        filename_time_str = local_dt.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        screenshot_path = os.path.join(\n",
    "            SCREENSHOT_DIR, f\"screenshot_{filename_time_str}_count{raw_count}.jpg\"\n",
    "        )\n",
    "        cv2.imwrite(screenshot_path, annotated)\n",
    "        last_screenshot_time = now_epoch\n",
    "        print(f\"Saved: {screenshot_path}\")\n",
    "\n",
    "    # Live preview (real-time, no clear_output flicker)\n",
    "    if LIVE_PREVIEW and frame_idx % PREVIEW_EVERY == 0:\n",
    "        now_preview = time.time()\n",
    "        dt = now_preview - last_preview_time\n",
    "        if dt > 0:\n",
    "            preview_fps = 1.0 / dt\n",
    "        last_preview_time = now_preview\n",
    "        \n",
    "        # No clear_output to avoid flicker\n",
    "        print(\n",
    "            f\"Frame {frame_idx} | FPS:{preview_fps:.1f} | raw={raw_count}, smooth={smooth_count:.1f}, filtered={filtered_out}\"\n",
    "        )\n",
    "        rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "        display_handle.update(Image.fromarray(rgb))\n",
    "\n",
    "    # File mode: write video\n",
    "    if MODE == \"file\":\n",
    "        out.write(annotated)\n",
    "\n",
    "    frame_idx += 1\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CLEANUP\n",
    "# ============================================================\n",
    "\n",
    "if cap is not None:\n",
    "    cap.release()\n",
    "if MODE == \"file\":\n",
    "    out.release()\n",
    "\n",
    "log_file.flush()\n",
    "log_file.close()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"Done! Processed {frame_idx} frames.\")\n",
    "print(f\"Log: {LOG_PATH}\")\n",
    "if MODE == \"file\":\n",
    "    print(f\"Video: {output_video}\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
